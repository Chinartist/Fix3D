{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhouxiaoyu/anaconda3/envs/ose/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers import AutoPipelineForImage2Image\n",
    "from diffusers.utils import load_image\n",
    "import torch\n",
    "from diffusers.utils import make_image_grid, load_image\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, CLIPTextModel,CLIPVisionModelWithProjection,CLIPVisionModel\n",
    "from diffusers import DDPMScheduler,DDIMScheduler,EulerDiscreteScheduler\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "from diffusers.utils.peft_utils import set_weights_and_activate_adapters\n",
    "from peft import LoraConfig\n",
    "from diffusers.models.attention_processor import (\n",
    "            AttnProcessor,\n",
    "            AttnProcessor2_0,\n",
    "            IPAdapterAttnProcessor,\n",
    "            IPAdapterAttnProcessor2_0,\n",
    "        )\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "from typing import List, Optional, Union\n",
    "def retrieve_timesteps(\n",
    "    scheduler,\n",
    "    num_inference_steps: Optional[int] = None,\n",
    "    device: Optional[Union[str, torch.device]] = None,\n",
    "    timesteps: Optional[List[int]] = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls the scheduler's `set_timesteps` method and retrieves timesteps from the scheduler after the call. Handles\n",
    "    custom timesteps. Any kwargs will be supplied to `scheduler.set_timesteps`.\n",
    "\n",
    "    Args:\n",
    "        scheduler (`SchedulerMixin`):\n",
    "            The scheduler to get timesteps from.\n",
    "        num_inference_steps (`int`):\n",
    "            The number of diffusion steps used when generating samples with a pre-trained model. If used,\n",
    "            `timesteps` must be `None`.\n",
    "        device (`str` or `torch.device`, *optional*):\n",
    "            The device to which the timesteps should be moved to. If `None`, the timesteps are not moved.\n",
    "        timesteps (`List[int]`, *optional*):\n",
    "                Custom timesteps used to support arbitrary spacing between timesteps. If `None`, then the default\n",
    "                timestep spacing strategy of the scheduler is used. If `timesteps` is passed, `num_inference_steps`\n",
    "                must be `None`.\n",
    "\n",
    "    Returns:\n",
    "        `Tuple[torch.Tensor, int]`: A tuple where the first element is the timestep schedule from the scheduler and the\n",
    "        second element is the number of inference steps.\n",
    "    \"\"\"\n",
    "    if timesteps is not None:\n",
    "        accepts_timesteps = \"timesteps\" in set(inspect.signature(scheduler.set_timesteps).parameters.keys())\n",
    "        if not accepts_timesteps:\n",
    "            raise ValueError(\n",
    "                f\"The current scheduler class {scheduler.__class__}'s `set_timesteps` does not support custom\"\n",
    "                f\" timestep schedules. Please check whether you are using the correct scheduler.\"\n",
    "            )\n",
    "        scheduler.set_timesteps(timesteps=timesteps, device=device, **kwargs)\n",
    "        timesteps = scheduler.timesteps\n",
    "        num_inference_steps = len(timesteps)\n",
    "    else:\n",
    "        scheduler.set_timesteps(num_inference_steps, device=device, **kwargs)\n",
    "        timesteps = scheduler.timesteps\n",
    "    return timesteps, num_inference_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from safetensors import safe_open\n",
    "# with safe_open(\"/nvme0/public_data/Occupancy/proj/cache/stabilityai/sd-turbo/sd_turbo.safetensors\", framework=\"pt\", device=0) as f:\n",
    "#     for k in f.keys():\n",
    "#         print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhouxiaoyu/anaconda3/envs/ose/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 17.32it/s]it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.10it/s]it/s]\n",
      "Loading pipeline components...:  89%|████████▉ | 8/9 [00:02<00:00,  2.71it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading pipeline components...: 100%|██████████| 9/9 [00:02<00:00,  3.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FlowMatchEulerDiscreteScheduler\n",
    "from diffusers import StableDiffusion3Pipeline,StableDiffusion3Img2ImgPipeline\n",
    "from peft.utils import get_peft_model_state_dict\n",
    "pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-large-turbo\", torch_dtype=torch.bfloat16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.9819, 0.9624, 0.9414, 0.9187, 0.8940, 0.8672, 0.8379, 0.8057,\n",
       "        0.7702, 0.7310, 0.6872, 0.6382, 0.5829, 0.5201, 0.4479, 0.3644, 0.2663,\n",
       "        0.1498, 0.0089, 0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.scheduler.sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    image = pipe(\n",
    "        \"Family guy, shut up Meg\",\n",
    "        num_inference_steps=20,\n",
    "        guidance_scale=0.0,\n",
    "    ).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timesteps(scheduler, num_inference_steps, strength, device):\n",
    "    # get the original timestep using init_timestep\n",
    "    init_timestep = min(int(num_inference_steps * strength), num_inference_steps)\n",
    "\n",
    "    t_start = max(num_inference_steps - init_timestep, 0)\n",
    "    timesteps = scheduler.timesteps[t_start * scheduler.order :]\n",
    "\n",
    "    return timesteps, num_inference_steps - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# image = Image.open(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/2_car/CAM_FRONT_RIGHT/004.jpg\")\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.load(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/2_car_mask/CAM_FRONT_RIGHT/004.npy\")\n",
    "# Image.fromarray(mask.astype(np.uint8)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# scene_dir = \"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/static_render_result/2_scene\"\n",
    "# car_dir = \"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/2_car\"\n",
    "# car_mask_dir = \"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/2_car_mask\"\n",
    "# for cam in os.listdir(scene_dir):\n",
    "#     for f in os.listdir(os.path.join(scene_dir, cam)):\n",
    "#         if f.endswith(\".jpg\"):\n",
    "#             scene_path = os.path.join(scene_dir, cam, f)\n",
    "#             car_path = os.path.join(car_dir, cam, f)\n",
    "#             car_mask_path = os.path.join(car_mask_dir, cam, f.replace(\".jpg\", \".npy\"))\n",
    "#             scene_image = np.array(Image.open(scene_path))\n",
    "#             car_image =np.array(Image.open(car_path))\n",
    "#             mask = np.load(car_mask_path)>0\n",
    "#             #创建一个5*5的值为1的卷积核\n",
    "#             kernel = np.ones((3,3),np.uint8)\n",
    "#             #腐蚀运算，iteration=1,迭代腐蚀1次\n",
    "#             mask = cv2.erode(mask.astype(np.uint8),kernel,iterations=2)>0\n",
    "#             mask = mask*(car_image!=255).any(-1)\n",
    "#             mask = mask>0\n",
    "#             scene_image[mask]=car_image[mask]\n",
    "#             scene_image = Image.fromarray(scene_image)\n",
    "#             save_dir = os.path.join(scene_dir.replace(\"static_render_result\",\"combine\"),cam)\n",
    "#             os.makedirs(save_dir,exist_ok=True)\n",
    "#             scene_image.save(os.path.join(save_dir,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x =np.load(\"/nvme0/public_data/Occupancy/proj/vis/gaussian-splatting/inputs/full/scene0000_00/semantic_mask/0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**14*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "def canny_from_pil(image, low_threshold=100, high_threshold=200):\n",
    "    image = np.array(image)\n",
    "    image = cv2.Canny(image, low_threshold, high_threshold)\n",
    "    image = image[:, :, None]\n",
    "    image = np.concatenate([image, image, image], axis=2)\n",
    "    print(np.unique(image))\n",
    "    \n",
    "    control_image = Image.fromarray(image)\n",
    "    return control_image\n",
    "image = Image.open(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/ourscene/gt/00004.png\")\n",
    "image = canny_from_pil(image)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch stable-diffusion-v1-5/stable-diffusion-v1-5: Error no file named diffusion_pytorch_model.safetensors found in directory stable-diffusion-v1-5/stable-diffusion-v1-5.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DownEncoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (up_blocks): ModuleList(\n",
       "      (0-1): 2 x UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UpDecoderBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae= AutoencoderKL.from_pretrained(\"stable-diffusion-v1-5/stable-diffusion-v1-5\", subfolder=\"vae\").cuda()\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vae.decoder.conv_out.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "image =load_image(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/3DRealCar_Renders/image_pairs_output/2024_05_26_19_01_07/gt/00000.png\").resize((1024, 1024))\n",
    "input_image =F.normalize( F.to_tensor(image), mean=[0.5], std=[0.5]).unsqueeze(0).cuda()\n",
    "# with torch.no_grad():\n",
    "vae.requires_grad_(False)\n",
    "with torch.inference_mode():\n",
    "    latents = vae.encode(input_image).latent_dist.sample() \n",
    "    output_image = (vae.decode(latents, return_dict=False, generator=None)[\n",
    "                        0\n",
    "                    ]).clamp(-1, 1)\n",
    "output_image = (output_image + 1) / 2.0\n",
    "output_image = (output_image * 255).to(torch.uint8)\n",
    "output_image = output_image.permute(0, 2, 3, 1)[0].cpu().numpy()\n",
    "output_image = Image.fromarray(output_image)\n",
    "output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/3DRealCar_Renders/image_pairs_output/2024_07_21_17_41_23/renders/00010.png\").resize((512, 512))\n",
    "scheduler =EulerDiscreteScheduler().from_pretrained(\"stabilityai/sd-turbo\", subfolder=\"scheduler\")\n",
    "num_inference_steps = 5\n",
    "strength = 1.0\n",
    "print(f\"Num inference steps all: {num_inference_steps}\")\n",
    "print(f\"Strength: {strength}\")\n",
    "timesteps, num_inference_steps = retrieve_timesteps(scheduler, num_inference_steps, \"cuda\", None)\n",
    "timesteps, num_inference_steps = get_timesteps(scheduler,num_inference_steps, strength, \"cuda\")\n",
    "latent_timestep = torch.tensor(timesteps).cuda()\n",
    "with torch.no_grad():\n",
    "    input_image = F.normalize( F.to_tensor(image), mean=[0.5], std=[0.5]).unsqueeze(0).cuda()\n",
    "    latents = vae.encode(input_image).latent_dist.sample() * vae.config.scaling_factor\n",
    "    noise = randn_tensor(latents.shape, generator=None, device=latents.device, dtype=latents.dtype)\n",
    "    # latents=scheduler.add_noise(latents, noise, latent_timestep[0:1])\n",
    "    latents = latents+noise* scheduler.sigmas[3] \n",
    "    output_image = (vae.decode(latents / vae.config.scaling_factor, return_dict=False, generator=None)[\n",
    "                0\n",
    "            ]).clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = (output_image + 1) / 2.0\n",
    "output_image = (output_image * 255).to(torch.uint8)\n",
    "output_image = output_image.permute(0, 2, 3, 1)[0].cpu().numpy()\n",
    "output_image = Image.fromarray(output_image, mode=\"RGB\")\n",
    "output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image\n",
    "url = \"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/JiaLei/飞书20250604-153159/001.jpg\"\n",
    "init_image = load_image(url).resize((512, 512))\n",
    "\n",
    "prompt = \"a high quality professional photograph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdturbo_pipe = AutoPipelineForImage2Image.from_pretrained(\"stabilityai/sd-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "sdturbo_pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdturbo_pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m image = init_image\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     image = \u001b[43msdturbo_pipe\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33ma high quality professional photograph\u001b[39m\u001b[33m\"\u001b[39m,  image=image, num_inference_steps=num_inference_steps, strength=strength, guidance_scale=\u001b[32m0\u001b[39m).images[\u001b[32m0\u001b[39m]\n\u001b[32m      6\u001b[39m     make_image_grid([init_image, image], rows=\u001b[32m1\u001b[39m, cols=\u001b[32m2\u001b[39m).save(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/nvme0/public_data/Occupancy/proj/img2img-turbo/cat_turbo_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_inference_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrength\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sdturbo_pipe' is not defined"
     ]
    }
   ],
   "source": [
    "num_inference_steps = 2\n",
    "strength = 0.5\n",
    "image = init_image\n",
    "for i in range(10):\n",
    "    image = sdturbo_pipe(\"a high quality professional photograph\",  image=image, num_inference_steps=num_inference_steps, strength=strength, guidance_scale=0).images[0]\n",
    "    make_image_grid([init_image, image], rows=1, cols=2).save(f\"/nvme0/public_data/Occupancy/proj/img2img-turbo/cat_turbo_{i}_{num_inference_steps}_{strength}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 5/5 [00:01<00:00,  4.21it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AutoPipelineForImage2Image\n",
    "from diffusers.utils import make_image_grid, load_image\n",
    "\n",
    "sd21pipeline = AutoPipelineForImage2Image.from_pretrained(\n",
    "    \"/nvme0/public_data/Occupancy/proj/img2img-turbo/stabilityai/sd-turbo\", torch_dtype=torch.float16)\n",
    "sd21pipeline.enable_model_cpu_offload()\n",
    "# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\n",
    "sd21pipeline.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# pass prompt and image to pipeline\n",
    "image = init_image\n",
    "for i in range(1):\n",
    "    image = sd21pipeline(\"a high quality professional photograph of a car\", image=image, num_inference_steps=2,strength=0.5,guidance_scale=0).images[0]\n",
    "    make_image_grid([init_image, image], rows=1, cols=2).save(f\"/nvme0/public_data/Occupancy/proj/img2img-turbo/outputs/{i}_sd21.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import AutoPipelineForImage2Image\n",
    "from diffusers.utils import make_image_grid, load_image\n",
    "\n",
    "pipeline = AutoPipelineForImage2Image.from_pretrained(\n",
    "    \"stable-diffusion-v1-5/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=False\n",
    ")\n",
    "pipeline.enable_model_cpu_offload()\n",
    "# remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed\n",
    "pipeline.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "# prepare image\n",
    "# url = \"/nvme0/public_data/Occupancy/proj/img2img-turbo/img2img-init.png\"\n",
    "# init_image = load_image(url)\n",
    "\n",
    "# prompt = \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\"\n",
    "\n",
    "# # pass prompt and image to pipeline\n",
    "# image = pipeline(prompt, image=init_image,strength=0.5).images[0]\n",
    "# make_image_grid([init_image, image], rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipeline(\"a high quality professional photograph of a car\", image=init_image,strength=0.5, guidance_scale=4).images[0]\n",
    "make_image_grid([init_image, image], rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image = Image.open(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/1/CAM_FRONT_RIGHT/001.jpg\")\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhouxiaoyu/anaconda3/envs/v2v/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zhouxiaoyu/anaconda3/envs/v2v/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/zhouxiaoyu/anaconda3/envs/v2v/lib/python3.11/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "import lpips\n",
    "import torch\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "loss_fn = lpips.LPIPS(net='vgg')\n",
    "image1 = x\n",
    "image2 = x + 0.1 * torch.rand_like(x)\n",
    "loss = loss_fn(image1, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load(\"/home/zhouxiaoyu/anaconda3/envs/v2v/lib/python3.11/site-packages/lpips/weights/v0.1/vgg.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patch_embedding.weight',\n",
       " 'patch_embedding.bias',\n",
       " 'condition_embedder.time_embedder.linear_1.lora_A.default.weight',\n",
       " 'condition_embedder.time_embedder.linear_1.lora_B.default.weight',\n",
       " 'condition_embedder.time_embedder.linear_2.lora_A.default.weight',\n",
       " 'condition_embedder.time_embedder.linear_2.lora_B.default.weight',\n",
       " 'condition_embedder.time_proj.lora_A.default.weight',\n",
       " 'condition_embedder.time_proj.lora_B.default.weight',\n",
       " 'condition_embedder.text_embedder.linear_1.lora_A.default.weight',\n",
       " 'condition_embedder.text_embedder.linear_1.lora_B.default.weight',\n",
       " 'condition_embedder.text_embedder.linear_2.lora_A.default.weight',\n",
       " 'condition_embedder.text_embedder.linear_2.lora_B.default.weight',\n",
       " 'blocks.0.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.0.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.0.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.0.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.0.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.0.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.0.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.0.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.0.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.0.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.0.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.0.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.0.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.0.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.0.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.0.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.0.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.0.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.0.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.0.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.1.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.1.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.1.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.1.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.1.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.1.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.1.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.1.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.1.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.1.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.1.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.1.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.1.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.1.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.1.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.1.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.1.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.1.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.1.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.1.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.2.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.2.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.2.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.2.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.2.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.2.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.2.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.2.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.2.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.2.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.2.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.2.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.2.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.2.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.2.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.2.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.2.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.2.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.2.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.2.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.3.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.3.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.3.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.3.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.3.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.3.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.3.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.3.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.3.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.3.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.3.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.3.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.3.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.3.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.3.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.3.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.3.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.3.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.3.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.3.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.4.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.4.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.4.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.4.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.4.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.4.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.4.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.4.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.4.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.4.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.4.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.4.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.4.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.4.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.4.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.4.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.4.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.4.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.4.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.4.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.5.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.5.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.5.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.5.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.5.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.5.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.5.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.5.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.5.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.5.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.5.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.5.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.5.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.5.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.5.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.5.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.5.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.5.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.5.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.5.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.6.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.6.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.6.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.6.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.6.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.6.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.6.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.6.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.6.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.6.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.6.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.6.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.6.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.6.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.6.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.6.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.6.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.6.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.6.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.6.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.7.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.7.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.7.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.7.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.7.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.7.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.7.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.7.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.7.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.7.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.7.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.7.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.7.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.7.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.7.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.7.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.7.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.7.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.7.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.7.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.8.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.8.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.8.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.8.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.8.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.8.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.8.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.8.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.8.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.8.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.8.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.8.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.8.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.8.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.8.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.8.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.8.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.8.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.8.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.8.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.9.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.9.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.9.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.9.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.9.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.9.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.9.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.9.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.9.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.9.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.9.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.9.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.9.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.9.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.9.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.9.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.9.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.9.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.9.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.9.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.10.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.10.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.10.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.10.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.10.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.10.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.10.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.10.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.10.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.10.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.10.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.10.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.10.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.10.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.10.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.10.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.10.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.10.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.10.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.10.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.11.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.11.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.11.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.11.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.11.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.11.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.11.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.11.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.11.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.11.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.11.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.11.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.11.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.11.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.11.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.11.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.11.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.11.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.11.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.11.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.12.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.12.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.12.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.12.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.12.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.12.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.12.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.12.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.12.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.12.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.12.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.12.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.12.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.12.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.12.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.12.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.12.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.12.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.12.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.12.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.13.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.13.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.13.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.13.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.13.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.13.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.13.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.13.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.13.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.13.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.13.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.13.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.13.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.13.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.13.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.13.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.13.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.13.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.13.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.13.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.14.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.14.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.14.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.14.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.14.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.14.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.14.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.14.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.14.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.14.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.14.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.14.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.14.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.14.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.14.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.14.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.14.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.14.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.14.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.14.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.15.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.15.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.15.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.15.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.15.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.15.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.15.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.15.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.15.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.15.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.15.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.15.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.15.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.15.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.15.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.15.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.15.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.15.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.15.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.15.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.16.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.16.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.16.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.16.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.16.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.16.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.16.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.16.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.16.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.16.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.16.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.16.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.16.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.16.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.16.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.16.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.16.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.16.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.16.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.16.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.17.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.17.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.17.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.17.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.17.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.17.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.17.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.17.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.17.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.17.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.17.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.17.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.17.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.17.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.17.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.17.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.17.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.17.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.17.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.17.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.18.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.18.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.18.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.18.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.18.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.18.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.18.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.18.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.18.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.18.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.18.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.18.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.18.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.18.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.18.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.18.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.18.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.18.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.18.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.18.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.19.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.19.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.19.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.19.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.19.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.19.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.19.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.19.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.19.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.19.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.19.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.19.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.19.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.19.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.19.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.19.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.19.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.19.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.19.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.19.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.20.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.20.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.20.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.20.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.20.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.20.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.20.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.20.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.20.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.20.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.20.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.20.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.20.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.20.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.20.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.20.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.20.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.20.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.20.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.20.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.21.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.21.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.21.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.21.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.21.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.21.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.21.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.21.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.21.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.21.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.21.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.21.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.21.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.21.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.21.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.21.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.21.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.21.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.21.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.21.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.22.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.22.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.22.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.22.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.22.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.22.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.22.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.22.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.22.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.22.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.22.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.22.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.22.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.22.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.22.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.22.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.22.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.22.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.22.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.22.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.23.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.23.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.23.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.23.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.23.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.23.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.23.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.23.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.23.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.23.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.23.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.23.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.23.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.23.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.23.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.23.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.23.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.23.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.23.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.23.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.24.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.24.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.24.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.24.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.24.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.24.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.24.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.24.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.24.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.24.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.24.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.24.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.24.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.24.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.24.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.24.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.24.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.24.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.24.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.24.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.25.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.25.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.25.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.25.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.25.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.25.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.25.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.25.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.25.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.25.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.25.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.25.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.25.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.25.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.25.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.25.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.25.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.25.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.25.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.25.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.26.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.26.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.26.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.26.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.26.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.26.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.26.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.26.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.26.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.26.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.26.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.26.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.26.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.26.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.26.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.26.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.26.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.26.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.26.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.26.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.27.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.27.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.27.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.27.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.27.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.27.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.27.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.27.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.27.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.27.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.27.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.27.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.27.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.27.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.27.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.27.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.27.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.27.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.27.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.27.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.28.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.28.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.28.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.28.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.28.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.28.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.28.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.28.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.28.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.28.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.28.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.28.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.28.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.28.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.28.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.28.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.28.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.28.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.28.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.28.ffn.net.2.lora_B.default.weight',\n",
       " 'blocks.29.attn1.to_q.lora_A.default.weight',\n",
       " 'blocks.29.attn1.to_q.lora_B.default.weight',\n",
       " 'blocks.29.attn1.to_k.lora_A.default.weight',\n",
       " 'blocks.29.attn1.to_k.lora_B.default.weight',\n",
       " 'blocks.29.attn1.to_v.lora_A.default.weight',\n",
       " 'blocks.29.attn1.to_v.lora_B.default.weight',\n",
       " 'blocks.29.attn1.to_out.0.lora_A.default.weight',\n",
       " 'blocks.29.attn1.to_out.0.lora_B.default.weight',\n",
       " 'blocks.29.attn2.to_q.lora_A.default.weight',\n",
       " 'blocks.29.attn2.to_q.lora_B.default.weight',\n",
       " 'blocks.29.attn2.to_k.lora_A.default.weight',\n",
       " 'blocks.29.attn2.to_k.lora_B.default.weight',\n",
       " 'blocks.29.attn2.to_v.lora_A.default.weight',\n",
       " 'blocks.29.attn2.to_v.lora_B.default.weight',\n",
       " 'blocks.29.attn2.to_out.0.lora_A.default.weight',\n",
       " 'blocks.29.attn2.to_out.0.lora_B.default.weight',\n",
       " 'blocks.29.ffn.net.0.proj.lora_A.default.weight',\n",
       " 'blocks.29.ffn.net.0.proj.lora_B.default.weight',\n",
       " 'blocks.29.ffn.net.2.lora_A.default.weight',\n",
       " 'blocks.29.ffn.net.2.lora_B.default.weight',\n",
       " 'proj_out.base_layer.weight',\n",
       " 'proj_out.base_layer.bias',\n",
       " 'proj_out.lora_A.default.weight',\n",
       " 'proj_out.lora_B.default.weight']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "sd = torch.load(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/outputs/pix2pix_turbo/stage0_render/checkpoints/model_10.pkl\")\n",
    "list(sd[\"state_dict_tf\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loss_utils import ssim,ms_ssim\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "image1 = Image.open(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/ourscene/gt/00000.png\")\n",
    "image2 = Image.open(\"/nvme0/public_data/Occupancy/proj/img2img-turbo/inputs/ourscene/renders/00000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = F.to_tensor(image1).unsqueeze(0)\n",
    "image2 = F.to_tensor(image2).unsqueeze(0)\n",
    "ssim_value =1- ssim(image1, image2,data_range=1.0, size_average=True)\n",
    "ms_ssim_value = 1 - ms_ssim(image1, image2, data_range=1.0, size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5890), tensor(0.4981))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim_value, ms_ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202.13000000000002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "77.17+116.06+8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
